{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cropping and Rotating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cmath import nan\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_rotate_dir(input_dir = 'input',output_dir='output', angle = -1.5, left = 135, upper =85, right = 600, lower = 390):\n",
    "    # read every image file from the input folder\n",
    "    for filename in glob.glob(input_dir+'/*.jpeg'):\n",
    "        # print(filename)\n",
    "        with Image.open(filename) as im:\n",
    "            # (left, upper, right, lower) = (100, 60, 630, 400)\n",
    "            rotated = im.rotate(angle, expand = 1)\n",
    "            im_final = rotated.crop((left, upper, right, lower))            \n",
    "            im_final.save(filename.replace(input_dir, output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters\n",
    "crop_rotate_dir(input_dir = '../test_img/',output_dir='output_test',left = 135, upper =85, right = 600, lower = 390)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input: filename of plate\n",
    "output: pd df of the ground truth for that plate\n",
    "\"\"\"\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def get_ground_truth(filename: str):\n",
    "    id = filename.split('_')[-1][:-5]\n",
    "    labels = pd.read_csv(f'labeled_dataset/{id}' + '/' + f'{id}_labels.csv', index_col=0)\n",
    "    return labels\n",
    "\n",
    "\"\"\"\n",
    "gaussian_kernel_size: greater = blurring in larger neighborhood\n",
    "gaussian_sigma: greater sigma = more blurring\n",
    "adp_th_block_size needs to be odd: greater = looking at local intensities in a larger neighborhood\n",
    "adp_th_const is a constant that is subtracted from the weighted mean; greater = effectively more noise reduction\n",
    "\"\"\"\n",
    "def load_and_preprocess_img(filename: str, gaussian_kernel_size: Tuple = (3,3), gaussian_sigma: float = 1.0, adp_th_block_size: int = 5, adp_th_const: int = 4):\n",
    "    img = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "    img_blurred = cv2.GaussianBlur(img, gaussian_kernel_size, gaussian_sigma)\n",
    "    img_th = cv2.adaptiveThreshold(img_blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, adp_th_block_size, adp_th_const)\n",
    "    return img_th\n",
    "\n",
    "\"\"\"\n",
    "exclude wells with black background\n",
    "\"\"\"\n",
    "def exclude_wells(col_idx, row_idx):\n",
    "    if ((col_idx == 2 or col_idx == 3) and row_idx == 12) or ((row_idx ==0 or row_idx == 15) and (col_idx==11 or col_idx ==12)) or (row_idx == 2 and col_idx==20):\n",
    "        return True\n",
    "    return False\n",
    "\"\"\"\n",
    "input: img or preprocessed img\n",
    "output: conceptually a matrix of 16 x 24, each entry is the isolated well image\n",
    "\"\"\"\n",
    "def isolate_each_well(img_th):\n",
    "    to_return = []\n",
    "    y = img_th.shape[0] / 16\n",
    "    x = img_th.shape[1] / 24\n",
    "    for row in np.arange(0, img_th.shape[0], y):\n",
    "        col_out = []\n",
    "        for col in np.arange(0, img_th.shape[1], x):\n",
    "            col_out.append(img_th[round(row):round(row+y),round(col):round(col+x)])\n",
    "        to_return.append(col_out)\n",
    "    return np.array(to_return, dtype=object)\n",
    "\n",
    "\"\"\"\n",
    "If one and only one particle is detected, report 1\n",
    "If no particle detected, report 0\n",
    "else: report -1 to indicate ambiguity\n",
    "\"\"\"\n",
    "def particle_detection_prediction(well_img):\n",
    "    nb_components = cv2.connectedComponentsWithStats(well_img, connectivity=8)\n",
    "    if nb_components[0] - 1 == 1:\n",
    "        pred = 1\n",
    "    elif nb_components[0] - 1 == 0:\n",
    "        pred = 0\n",
    "    else:\n",
    "        pred = -1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Uses particle detection to predict whether or not bead is present.\n",
    "Returns accuracy and a list of unsure well locations for each img (if particle_detection_prediction returns -1)\n",
    "    which means that more than one particle is detected in the well\n",
    "\"\"\"\n",
    "def melodys_pipeline(input_dir):\n",
    "    accuracy_list = []\n",
    "    unsure_dict = {}\n",
    "    # read every image file from the input folder\n",
    "    for filename in glob.glob(input_dir+'/*.jpeg'):\n",
    "        right = 0\n",
    "        wrong = 0\n",
    "        unsure = []\n",
    "        labels = get_ground_truth(filename)\n",
    "        img_th = load_and_preprocess_img(filename, (3,3), 1.0, 5, 4)\n",
    "        well_imgs = isolate_each_well(img_th)\n",
    "        for row in range(well_imgs.shape[0]):\n",
    "            for col in range(well_imgs.shape[1]):\n",
    "                if exclude_wells(col, row):\n",
    "                    continue\n",
    "                well = np.array(well_imgs[row,col])\n",
    "                pred = particle_detection_prediction(well)\n",
    "                if pred != -1:\n",
    "                    truth = labels.loc[(labels['COLUMN_ID']==col + 1) & (labels['ROW_ID']==row + 1),'LABEL'].tolist()[0]\n",
    "                    if truth == nan:\n",
    "                        continue\n",
    "                    if pred == truth:\n",
    "                        right += 1\n",
    "                    else:\n",
    "                        wrong += 1\n",
    "                else:\n",
    "                    unsure.append([row, col])\n",
    "        accuracy_list.append(right / (right + wrong + len(unsure)))\n",
    "        unsure_dict[filename] = unsure\n",
    "    return accuracy_list, unsure_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.10344827586206896, 0.08488063660477453, 0.10344827586206896],\n",
       " {'/Users/yiqingmelodywang/Desktop/CMU/Ginkgo/GinkgoCapstone/output_test220104_152235_862416.jpeg': [],\n",
       "  '/Users/yiqingmelodywang/Desktop/CMU/Ginkgo/GinkgoCapstone/output_test220322_134621_907015.jpeg': [],\n",
       "  '/Users/yiqingmelodywang/Desktop/CMU/Ginkgo/GinkgoCapstone/output_test220104_150753_862416.jpeg': []})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melodys_pipeline(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
